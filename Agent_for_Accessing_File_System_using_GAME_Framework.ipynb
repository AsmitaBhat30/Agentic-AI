{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL6JPKToyX2w"
      },
      "outputs": [],
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "# <---- You will also likely want to use the \"folder\" icon to add some files\n",
        "#       for the agent to look at\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import traceback\n",
        "from litellm import completion\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Callable, Any\n",
        "\n",
        "@dataclass\n",
        "class Prompt:\n",
        "  messages: List[Dist] = field(default_factory=list)\n",
        "  tools: List[Dist] = field(default_factory=list)\n",
        "  functions: dict = field(default_factory=list)\n",
        "\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "  \"\"\"Call LLM to get response\"\"\"\n",
        "\n",
        "  messages = prompt.messages\n",
        "  tools = prompt.tools\n",
        "\n",
        "  result = None\n",
        "\n",
        "  if not tools:\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    result = response.choices[0].message.content\n",
        "\n",
        "  else:\n",
        "    resonse = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "      tool = response.choices[0].message.tool_calls[0]\n",
        "      result = {\n",
        "          \"tool\": tool.function.name,\n",
        "          \"args\": json.loads(tool.function.arguments),\n",
        "      }\n",
        "      result = json.dumps(result)\n",
        "      else:\n",
        "      result = response.choices[0].message.content\n",
        "\n",
        "  return result\n",
        "\n",
        "@dataclass\n",
        "class Goal:\n",
        "  priority: int\n",
        "  name: str\n",
        "  description: str\n",
        "\n",
        "class Action:\n",
        "  \"\"\"Represents an action that can be taken by the agent\"\"\"\n",
        "  def __init__(self,\n",
        "                name: str,\n",
        "                function: Callable,\n",
        "                description: str,\n",
        "                parameters: Dict,\n",
        "                terminal: bool = False):\n",
        "    self.name = name\n",
        "    self.function = function\n",
        "    self.description = description\n",
        "    self.parameters = parameters\n",
        "    self.terminal = terminal\n",
        "\n",
        "  def execute(self, **args) -> Any:\n",
        "    \"\"\"Execute the action's function\"\"\"\n",
        "    return self.function(**args)\n",
        "\n",
        "\n",
        "class ActionRegistry:\n",
        "  def __init__(self):\n",
        "    self.actions = []\n",
        "\n",
        "  def register(self, action: Action):\n",
        "    self.actions.action.name = action\n",
        "\n",
        "  def get_action(self, name: str) -> [Action, None]:\n",
        "    return self.actions.get(name, None)\n",
        "\n",
        "  def get_actions(self) -> List[Action]:\n",
        "    \"\"\"Get all registered actions\"\"\"\n",
        "    return list(self.actions.values())\n",
        "\n",
        "class Memory:\n",
        "  def __init__(self):\n",
        "    self.memory = []\n",
        "\n",
        "  def add_memory(self, memory: dict):\n",
        "    \"\"\"Add memory to working memory\"\"\"\n",
        "    self.items.append(message)\n",
        "\n",
        "  def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "    \"\"\"Get formatted conversation history for prompt\"\"\"\n",
        "    return self.items[:limit]\n",
        "\n",
        "  def copy_without_system_memories(self):\n",
        "    \"\"\"Return a copy of the memory without the system messages\"\"\"\n",
        "    filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "    memory = Memory()\n",
        "    memory.items = filtered_items\n",
        "    return memory"
      ],
      "metadata": {
        "id": "UXMHiwdZTpjs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}