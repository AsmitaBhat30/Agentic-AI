{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "7RQptHklRqsQ",
        "outputId": "e7d6e1bb-a759-4fed-9058-9e141a6a30c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TimeoutException",
          "evalue": "Requesting secret OPENAI_API_KEY timed out. Secrets can only be fetched when running from the Colab UI.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2157717418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OPENAI_API_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutException\u001b[0m: Requesting secret OPENAI_API_KEY timed out. Secrets can only be fetched when running from the Colab UI."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "ZA6O83QwRvaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define core GAME components. Implemeting classes for Goals, Actions, ActionRegistry, Environment, Memory, AgentLangugae"
      ],
      "metadata": {
        "id": "3VIbLE2FS8ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Prompt:\n",
        "  messages: List[Dict] = field(default_factory=list)\n",
        "  tools: List[Dict] = field(default_factory=list)\n",
        "  functions: dict = field(default_factory=list)\n",
        "\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "  \"\"\"Call LLM to get response\"\"\"\n",
        "\n",
        "  messages = prompt.messages\n",
        "  tools = prompt.tools\n",
        "\n",
        "  result = None\n",
        "\n",
        "  if not tools:\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    result = response.choices[0].message.content\n",
        "\n",
        "  else:\n",
        "    resonse = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "      tool = response.choices[0].message.tool_calls[0]\n",
        "      result = {\n",
        "          \"tool\": tool.function.name,\n",
        "          \"args\": json.loads(tool.function.arguments),\n",
        "      }\n",
        "      result = json.dumps(result)\n",
        "    else:\n",
        "      result = response.choices[0].message.content\n",
        "\n",
        "  return result\n",
        "\n",
        "@dataclass\n",
        "class Goal:\n",
        "  priority: int\n",
        "  name: str\n",
        "  description: str\n",
        "\n",
        "class Action:\n",
        "  \"\"\"Represents an action that can be taken by the agent\"\"\"\n",
        "  def __init__(self,\n",
        "                name: str,\n",
        "                function: Callable,\n",
        "                description: str,\n",
        "                parameters: Dict,\n",
        "                terminal: bool = False):\n",
        "    self.name = name\n",
        "    self.function = function\n",
        "    self.description = description\n",
        "    self.parameters = parameters\n",
        "    self.terminal = terminal\n",
        "\n",
        "  def execute(self, **args) -> Any:\n",
        "    \"\"\"Execute the action's function\"\"\"\n",
        "    return self.function(**args)\n",
        "\n",
        "\n",
        "class ActionRegistry:\n",
        "  def __init__(self):\n",
        "    self.actions = {}\n",
        "\n",
        "  def register(self, action: Action):\n",
        "    self.actions[action.name] = action\n",
        "\n",
        "  def get_action(self, name: str):\n",
        "    return self.actions.get(name, None)\n",
        "\n",
        "  def get_actions(self) -> List[Action]:\n",
        "    \"\"\"Get all registered actions\"\"\"\n",
        "    return list(self.actions.values())\n",
        "\n",
        "class Memory:\n",
        "  def __init__(self):\n",
        "    self.items = []\n",
        "\n",
        "  def add_memory(self, memory: dict):\n",
        "    \"\"\"Add memory to working memory\"\"\"\n",
        "    self.items.append(memory)\n",
        "\n",
        "  def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "    \"\"\"Get formatted conversation history for prompt\"\"\"\n",
        "    return self.items[:limit]\n",
        "\n",
        "  def copy_without_system_memories(self):\n",
        "    \"\"\"Return a copy of the memory without the system messages\"\"\"\n",
        "    filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "    memory = Memory()\n",
        "    memory.items = filtered_items\n",
        "    return memory\n",
        "\n",
        "class Environment:\n",
        "  def execute_action(self, action: Action, args: dict) -> dict:\n",
        "    \"\"\"Execute an action and return the result\"\"\"\n",
        "    try:\n",
        "      result = action.execute(**args)\n",
        "      return self.format_result(result)\n",
        "    except Exception as e:\n",
        "      return {\n",
        "          \"tool_executed\": False,\n",
        "          \"error\": str(e),\n",
        "          \"traceback\": traceback.format_exc(),\n",
        "      }\n",
        "\n",
        "  def format_result(self, result: Any) -> dict:\n",
        "    \"\"\"Format the result with metadata\"\"\"\n",
        "    return {\n",
        "        \"tool_executed\": True,\n",
        "        \"result\": result,\n",
        "        \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\"),\n",
        "    }\n",
        "\n",
        "class AgentLanguage:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def construct_prompt(self,\n",
        "                       actions: List[Action],\n",
        "                       environment: Environment,\n",
        "                       goals: List[Goal],\n",
        "                       memory: Memory) -> Prompt:\n",
        "    raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "  def parse_response(self, response: str) -> dict:\n",
        "    raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "class AgentFunctionCallingActionLanguage(AgentLanguage):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def format_goals(self, goals: List[Goal]) -> List:\n",
        "    # Map all goals to a single string that concatenates their description\n",
        "    # and combine into a single message of type system\n",
        "    sep = \"\\n-----------------\\n\"\n",
        "    goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": goal_instructions}\n",
        "        ]\n",
        "\n",
        "  def format_memory(self, memory: Memory) -> List:\n",
        "    \"\"\"Generate response from language model\"\"\"\n",
        "    # Map all environment results to a role:user messages\n",
        "    # Map all assistant messages to a role:assistant messages\n",
        "    # Map all user messages to a role:user messages\n",
        "    items = memory.get_memories()\n",
        "    mapped_items = []\n",
        "    for item in items:\n",
        "\n",
        "      content = item.get(\"content\", None)\n",
        "      if not content:\n",
        "        content = json.dumps(item, indent=4)\n",
        "\n",
        "      if item[\"type\"] == \"assistant\":\n",
        "        mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "      elif item[\"type\"] == \"environment\":\n",
        "        mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "      else:\n",
        "        mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "    return mapped_items\n",
        "\n",
        "  def format_actions(self, actions: List[Action]) -> List:\n",
        "\n",
        "    tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": action.name,\n",
        "                \"description\": action.description[:1024],\n",
        "                \"parameters\": action.parameters,\n",
        "            },\n",
        "        }for action in actions\n",
        "    ]\n",
        "    return tools\n",
        "\n",
        "\n",
        "  def construct_prompt(self,\n",
        "                       actions: List[Action],\n",
        "                       environment: Environment,\n",
        "                       goals: List[Goal],\n",
        "                       memory: Memory) -> Prompt:\n",
        "\n",
        "    prompt = []\n",
        "    prompt += self.format_goals(goals)\n",
        "    prompt += self.format_memory(memory)\n",
        "\n",
        "    tools = self.format_actions(actions)\n",
        "\n",
        "    return Prompt(prompt, tools)\n",
        "\n",
        "  def adapt_prompt_after_parsing_error(self,\n",
        "                                       prompt: Prompt,\n",
        "                                       response: str,\n",
        "                                       traceback: str,\n",
        "                                       error: Any,\n",
        "                                       retries_left: int) -> Prompt:\n",
        "\n",
        "    return prompt\n",
        "\n",
        "  def parse_response(self, response: str) -> dict:\n",
        "\n",
        "    try:\n",
        "      return json.loads(response)\n",
        "    except Exception as e:\n",
        "      return {\n",
        "          \"tool\": \"terminate\",\n",
        "          \"args\": {\"message\": response},\n",
        "      }\n",
        "\n",
        "class Agent:\n",
        "  def __init__(self,\n",
        "               goals: List[Goal],\n",
        "               agent_language: AgentLanguage,\n",
        "               action_registry: ActionRegistry,\n",
        "               generate_response: Callable[[Prompt], str],\n",
        "               environment: Environment):\n",
        "\n",
        "    \"\"\"\n",
        "    Initialize the agent with it's core GAME components\n",
        "    \"\"\"\n",
        "    self.goals = goals\n",
        "    self.agent_language = agent_language\n",
        "    self.actions = action_registry\n",
        "    self.generate_response = generate_response\n",
        "    self.environment = environment\n",
        "\n",
        "  def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "    \"\"\"\n",
        "    Build prompt with memory context\"\"\"\n",
        "    return self.agent_language.construct_prompt(\n",
        "        actions=actions.get_actions(),\n",
        "        environment=self.environment,\n",
        "        goals=goals,\n",
        "        memory=memory,\n",
        "    )\n",
        "\n",
        "  def get_action(self, response):\n",
        "    invocation = self.agent_language.parse_response(response)\n",
        "    action = self.actions.get_action(invocation[\"tool\"])\n",
        "    return action, invocation\n",
        "\n",
        "  def should_terminate(self, response: str) -> bool:\n",
        "    action_def, _ = self.get_action(response)\n",
        "    return action_def.terminal\n",
        "\n",
        "  def set_current_task(self, memory: Memory, task: str):\n",
        "    memory.add_memory({\n",
        "        \"type\": \"user\",\n",
        "        \"content\": task\n",
        "    })\n",
        "\n",
        "  def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "    \"\"\"\n",
        "    Update memory with agent's decision and the environment's response\n",
        "    \"\"\"\n",
        "\n",
        "    new_memories = [\n",
        "        {\n",
        "            \"type\": \"assistant\",\n",
        "            \"content\": response,\n",
        "        },\n",
        "        {\n",
        "            \"type\": \"environment\",\n",
        "            \"content\": result,\n",
        "        }\n",
        "    ]\n",
        "    for m in new_memories:\n",
        "      memory.add_memory(m)\n",
        "\n",
        "  def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "    response = self.generate_response(full_prompt)\n",
        "    return response\n",
        "\n",
        "  def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "    \"\"\"\n",
        "    Execute the GAME loop for this agent with a maximum iteration limit.\n",
        "    \"\"\"\n",
        "    memory = memory or Memory()\n",
        "    self.set_current_task(memory, user_input)\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "\n",
        "      # Construct a prompt that includes the Goals, Actions, and the current Memory\n",
        "      prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "      print(\"Agent thinking...\")\n",
        "      # Generate a response from the LLM\n",
        "      response = self.prompt_llm_for_action(prompt)\n",
        "      print(f\"Agent Decision: {response}\")\n",
        "\n",
        "      # Determine which action the agent wants to execute\n",
        "      action, invocation = self.get_action(response)\n",
        "\n",
        "      # Execute the action in the environment\n",
        "      result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "      print(f\"Action Result: {result}\")\n",
        "\n",
        "      # Update the memory with the agent's decision and the environment's response\n",
        "      self.update_memory(memory, response, result)\n",
        "\n",
        "      # Check if the agent has decided to terminate\n",
        "      if self.should_terminate(response):\n",
        "        break\n",
        "\n",
        "    return memory\n",
        ""
      ],
      "metadata": {
        "id": "brqGO3s4S45u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V8fwxFcXS5ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GOAL:**\n",
        "\n",
        "To create an agent that can analyze Python files in a project and write a README file.\n",
        "\n",
        "Our README agent will:\n",
        "\n",
        "*   Look for Python files in a project directory\n",
        "*   Read the contents of each file\n",
        "*   Analyze what it finds\n",
        "*   Generate a README based on its analysis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IZkOiyXpOTTT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJVtknTpPJw8"
      },
      "outputs": [],
      "source": [
        "goals = [\n",
        "    Goal(\n",
        "        priority=1,\n",
        "        name=\"Gather Information\",\n",
        "        description=\"Read each file in the project\"\n",
        "    ),\n",
        "    Goal(\n",
        "        priority=1,\n",
        "        name=\"Terminate\",\n",
        "        description=\"Call the terminate call when you have read all the files \"\n",
        "                   \"and provide the content of the README in the terminate message\"\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actions:\n",
        "\n",
        "*   List project files\n",
        "*   Read project files\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4j0ZhQbBSbpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_project_file(name: str) -> str:\n",
        "    with open(name, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def list_project_files() -> List[str]:\n",
        "    return sorted([file for file in os.listdir(\".\")\n",
        "                  if file.endswith(\".py\")])\n",
        "\n",
        "# Register these actions with clear descriptions\n",
        "action_registry = ActionRegistry()\n",
        "action_registry.register(Action(\n",
        "    name=\"list_project_files\",\n",
        "    function=list_project_files,\n",
        "    description=\"Lists all files in the project.\",\n",
        "    parameters={},\n",
        "    terminal=False\n",
        "))\n",
        "\n",
        "action_registry.register(Action(\n",
        "    name=\"read_project_file\",\n",
        "    function=read_project_file,\n",
        "    description=\"Reads a file from the project.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"name\"]\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "\n",
        "action_registry.register(Action(\n",
        "    name=\"terminate\",\n",
        "    function=lambda message: f\"{message}\\nTerminating...\",\n",
        "    description=\"Terminates the session and prints the message to the user.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": []\n",
        "    },\n",
        "    terminal=True\n",
        "))"
      ],
      "metadata": {
        "id": "vlsqfVPzStUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing AgentLangugae: *Function Calling* vs *Programmatic Prompting*\n",
        "\n",
        "For this use case, we choose Function Calling\n",
        "\n",
        "The AgentLanguage will:\n",
        "\n",
        "*   Format our goals as system messages\n",
        "*   Present our actions as function definitions\n",
        "*   Maintain conversation history in the memory\n",
        "*   Parse function calls from the LLMâ€™s responses"
      ],
      "metadata": {
        "id": "XKcBvS35U0qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_language = AgentFunctionCallingActionLanguage()"
      ],
      "metadata": {
        "id": "tyyaC41mULFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the Environment, Assembling and Running the Agent"
      ],
      "metadata": {
        "id": "cT1hRlIjVkz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "environment = Environment()\n",
        "\n",
        "# Create an agent instance with our components\n",
        "agent = Agent(\n",
        "    goals=goals,\n",
        "    agent_language=AgentFunctionCallingActionLanguage(),\n",
        "    action_registry=action_registry,\n",
        "    generate_response=generate_response,\n",
        "    environment=environment\n",
        ")\n",
        "\n",
        "# Run the agent with our task\n",
        "user_input = \"Write a README for this project.\"\n",
        "final_memory = agent.run(user_input)"
      ],
      "metadata": {
        "id": "8lDtyM7gVix7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding the Typical Flow of the Code**\n",
        "\n",
        "1. First Iteration:\n",
        "\n",
        "\n",
        "\n",
        "* Agent constructs prompt with goals and available actions\n",
        "* LLM decides to list files first (logical starting point)\n",
        "* Environment executes list_project_files\n",
        "* Memory stores the list of files\n",
        "\n",
        "2. Middle Iterations:\n",
        "\n",
        "* Agent includes file list in context\n",
        "* LLM chooses files to read based on their names\n",
        "* Environment executes read_project_file for each chosen file\n",
        "* Memory accumulates file contents\n",
        "\n",
        "3. Final Iteration:\n",
        "\n",
        "* Agent determines it has enough information\n",
        "* LLM generates README content\n",
        "* Agent uses terminate action to deliver the result\n"
      ],
      "metadata": {
        "id": "tdnbk3vbWpsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    # Define the agent's goals\n",
        "    goals = [\n",
        "        Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n",
        "        Goal(priority=1, name=\"Terminate\", description=\"Call the terminate call when you have read all the files \"\n",
        "                                                       \"and provide the content of the README in the terminate message\")\n",
        "    ]\n",
        "\n",
        "    # Define the agent's language\n",
        "    agent_language = AgentFunctionCallingActionLanguage()\n",
        "\n",
        "    def read_project_file(name: str) -> str:\n",
        "        with open(name, \"r\") as f:\n",
        "            return f.read()\n",
        "\n",
        "    def list_project_files() -> List[str]:\n",
        "        return sorted([file for file in os.listdir(\".\") if file.endswith(\".py\")])\n",
        "\n",
        "    # Define the action registry and register some actions\n",
        "    action_registry = ActionRegistry()\n",
        "    action_registry.register(Action(\n",
        "        name=\"list_project_files\",\n",
        "        function=list_project_files,\n",
        "        description=\"Lists all files in the project.\",\n",
        "        parameters={},\n",
        "        terminal=False\n",
        "    ))\n",
        "    action_registry.register(Action(\n",
        "        name=\"read_project_file\",\n",
        "        function=read_project_file,\n",
        "        description=\"Reads a file from the project.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"name\"]\n",
        "        },\n",
        "        terminal=False\n",
        "    ))\n",
        "    action_registry.register(Action(\n",
        "        name=\"terminate\",\n",
        "        function=lambda message: f\"{message}\\nTerminating...\",\n",
        "        description=\"Terminates the session and prints the message to the user.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"message\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": []\n",
        "        },\n",
        "        terminal=True\n",
        "    ))\n",
        "\n",
        "    # Define the environment\n",
        "    environment = Environment()\n",
        "\n",
        "    # Create an agent instance\n",
        "    agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n",
        "\n",
        "    # Run the agent with user input\n",
        "    user_input = \"Write a README for this project.\"\n",
        "    final_memory = agent.run(user_input)\n",
        "\n",
        "    # Print the final memory\n",
        "    print(final_memory.get_memories())\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "FMMm7qNpWgYE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}